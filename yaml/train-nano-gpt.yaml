!dataclass:Config
# checkpoint and eval
eval_freq: 1000
eval_num_steps: 50
save_checkpoint: true
restore: "scratch"  # scratch | pre-trained | openai
gpt_type: "gpt2"
checkpoint_dir: "gs://flash-nano-gpt-bucket/data/checkpoints"
log_freq: 10
wandb: true
wandb_project_name: "flash-nano-gpt"
wandb_run_id: "nano-gpt"
# data
dataset_dir: "gs://flash-nano-gpt-bucket/data/openwebtext"
document_dataset: true
vocab_size: 50304
grad_accum_steps: 1
batch_size: 512
block_size: 1024
buffer_size: 128
prefetch: 2
# model
num_layers: 12
num_heads: 12
embd_dim: 768
dropout_rate: 0.0
use_bias: false
# Optimizer
num_iters: 150000
lr: 0.0006
lr_decay: true
lr_warmup_iters: 1000
lr_decay_iters: 150000
lr_min: 0.00006
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0
# training
device: "tpu" # cpu | gpu | tpu
seed: 2024 # happy new year !
amp: true
skip_infinite: true
jit: true
# sampling
samples_dir: "data/sampling"
num_samples: 10
max_new_tokens: 100
temperature: 1